#+TITLE:       Tensor Flow
#+AUTHOR:      Arturo Vivas
#+EMAIL:       arturo.vivas@gmail.com
#+DATE:        2016-11-27 So
#+URI:         /blog/%y/%m/%d/Tensor-flow-001
#+KEYWORDS:    tensor flow, linear algebra
#+TAGS:        tensor flow
#+LANGUAGE:    en
#+OPTIONS:     H:3 num:nil toc:nil \n:nil ::t |:t ^:nil -:nil f:t *:t <:t
#+DESCRIPTION: Introduction to Tensor Flow

The first very very very small program using TensorFlow. In the following lines we are going to perform a sum of two scalars. This may sound trivial, yet the important concept in the following code is the "graph" behind it.

#+BEGIN_SRC ipython :session mysession :exports both
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

session = tf.Session()

a = tf.constant(10, name="input_a")
b = tf.constant(20, name="input_b")
c = tf.add(a, b, name="add_c")

result = session.run(c)
(result)
#+END_SRC

#+RESULTS:
: 30

Here comes the interessting part, also pass auf! The small calculation Tensorflow we just did is the result of the computation of the *computational graph* defined in the code. The graphical visualization of the code would be the following:

#+BEGIN_SRC dot :file ./img/simple_graph.png :cmdline -Kdot -Tpng :export both
digraph G {

          rankdir=LR
	  splines=line
          nodesep=.05;
          x2 [label="10"];
          x1 [label="20"];
          a12 [label="10+30"];

          subgraph cluster_0 {
		  color=white;
                  node [style=solid,color=blue4, shape=circle];
		  x1 x2 ;
		  label = "layer 1 = Inputs";
	  }

	  subgraph cluster_1 {
		  color=white;
		  node [style=solid,color=red2, shape=circle];
		  a12 ;
		  label = "layer 2 = Output";
	  }

        x1 -> a12;
        x2 -> a12;

}
#+END_SRC

#+RESULTS:
[[file:./img/simple_graph.png]]
